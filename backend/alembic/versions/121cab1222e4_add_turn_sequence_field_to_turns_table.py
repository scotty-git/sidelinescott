"""Add turn_sequence field to turns table

Revision ID: 121cab1222e4
Revises: dd28a2237214
Create Date: 2025-07-11 17:19:16.843289

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '121cab1222e4'
down_revision: Union[str, Sequence[str], None] = 'dd28a2237214'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('email', sa.String(), nullable=False),
    sa.Column('hashed_password', sa.String(), nullable=True),
    sa.Column('is_master_admin', sa.Boolean(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.drop_table('ab_test_results')
    op.drop_table('prompt_usage')
    op.drop_table('ab_tests')
    op.drop_table('prompt_templates')
    op.alter_column('conversations', 'user_id',
               existing_type=sa.UUID(),
               comment=None,
               existing_comment='References Supabase Auth user ID (auth.users.id)',
               existing_nullable=False)
    op.alter_column('conversations', 'conversation_metadata',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.drop_index(op.f('idx_conversations_status'), table_name='conversations')
    op.drop_index(op.f('idx_conversations_user_id'), table_name='conversations')
    op.add_column('turns', sa.Column('turn_sequence', sa.Integer(), nullable=False))
    op.alter_column('turns', 'corrections',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True,
               existing_server_default=sa.text("'[]'::jsonb"))
    op.alter_column('turns', 'timing_breakdown',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.drop_index(op.f('idx_turns_conversation_id'), table_name='turns')
    op.drop_index(op.f('idx_turns_created_at'), table_name='turns')
    op.drop_index(op.f('idx_turns_speaker'), table_name='turns')
    op.drop_constraint(op.f('turns_conversation_id_fkey'), 'turns', type_='foreignkey')
    op.create_foreign_key(None, 'turns', 'conversations', ['conversation_id'], ['id'])
    op.drop_column('turns', 'corrections_applied')
    op.drop_column('turns', 'turn_index')
    op.drop_column('turns', 'cleaning_metadata')
    op.drop_column('turns', 'original_text')
    op.drop_column('turns', 'timestamp_utc')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('turns', sa.Column('timestamp_utc', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True))
    op.add_column('turns', sa.Column('original_text', sa.TEXT(), autoincrement=False, nullable=True))
    op.add_column('turns', sa.Column('cleaning_metadata', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True))
    op.add_column('turns', sa.Column('turn_index', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('turns', sa.Column('corrections_applied', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'[]'::jsonb"), autoincrement=False, nullable=True))
    op.drop_constraint(None, 'turns', type_='foreignkey')
    op.create_foreign_key(op.f('turns_conversation_id_fkey'), 'turns', 'conversations', ['conversation_id'], ['id'], ondelete='CASCADE')
    op.create_index(op.f('idx_turns_speaker'), 'turns', ['speaker'], unique=False)
    op.create_index(op.f('idx_turns_created_at'), 'turns', ['created_at'], unique=False)
    op.create_index(op.f('idx_turns_conversation_id'), 'turns', ['conversation_id'], unique=False)
    op.alter_column('turns', 'timing_breakdown',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('turns', 'corrections',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True,
               existing_server_default=sa.text("'[]'::jsonb"))
    op.drop_column('turns', 'turn_sequence')
    op.create_index(op.f('idx_conversations_user_id'), 'conversations', ['user_id'], unique=False)
    op.create_index(op.f('idx_conversations_status'), 'conversations', ['status'], unique=False)
    op.alter_column('conversations', 'conversation_metadata',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
    op.alter_column('conversations', 'user_id',
               existing_type=sa.UUID(),
               comment='References Supabase Auth user ID (auth.users.id)',
               existing_nullable=False)
    op.create_table('prompt_templates',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('template', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('variables', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('version', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('prompt_templates_pkey')),
    sa.UniqueConstraint('name', name=op.f('prompt_templates_name_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_table('ab_tests',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('prompt_a_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('prompt_b_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('traffic_split_percent', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('ended_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('ab_tests_pkey'))
    )
    op.create_table('prompt_usage',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('template_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('turn_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('conversation_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('rendered_prompt', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('variables_used', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('token_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('processing_time_ms', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('confidence_score', sa.VARCHAR(length=10), autoincrement=False, nullable=True),
    sa.Column('corrections_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('context_turns_used', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('prompt_usage_pkey'))
    )
    op.create_table('ab_test_results',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('test_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('prompt_variant', sa.VARCHAR(length=1), autoincrement=False, nullable=False),
    sa.Column('turn_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('processing_time_ms', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('confidence_score', sa.VARCHAR(length=10), autoincrement=False, nullable=True),
    sa.Column('corrections_count', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('success', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('ab_test_results_pkey'))
    )
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.drop_table('users')
    # ### end Alembic commands ###
